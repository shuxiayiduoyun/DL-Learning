{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "batch_size = 2\n",
    "sequence_length = 4\n",
    "d_embedding_in = 6\n",
    "d_embedding_out = 7"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T06:46:20.517779Z",
     "start_time": "2025-11-25T06:46:11.134478Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "5ab8cf16e14d0901",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T06:46:41.306123Z",
     "start_time": "2025-11-25T06:46:41.300806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(batch_size, sequence_length, d_embedding_in)\n",
    "x.shape"
   ],
   "id": "c3e3f2c86b3dfb2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T07:18:12.082756Z",
     "start_time": "2025-11-25T07:18:12.077086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# _NLinear is a simplified copy of delu.nn.NLinear:\n",
    "# https://yura52.github.io/delu/stable/api/generated/delu.nn.NLinear.html\n",
    "class _NLinear(nn.Module):\n",
    "    \"\"\"N *separate* linear layers for N feature embeddings.\n",
    "\n",
    "    In other words,\n",
    "    each feature embedding is transformed by its own dedicated linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n: int, in_features: int, out_features: int, bias: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = Parameter(torch.empty(n, in_features, out_features))\n",
    "        self.bias = Parameter(torch.empty(n, out_features)) if bias else None\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset the parameters.\"\"\"\n",
    "        d_in_rsqrt = self.weight.shape[-2] ** -0.5\n",
    "        nn.init.uniform_(self.weight, -d_in_rsqrt, d_in_rsqrt)\n",
    "        if self.bias is not None:\n",
    "            nn.init.uniform_(self.bias, -d_in_rsqrt, d_in_rsqrt)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Do the forward pass.\"\"\"\n",
    "        if x.ndim != 3:\n",
    "            raise ValueError(\n",
    "                '_NLinear supports only inputs with exactly one batch dimension,'\n",
    "                ' so `x` must have a shape like (BATCH_SIZE, N_FEATURES, D_EMBEDDING).'\n",
    "            )\n",
    "        assert x.shape[-(self.weight.ndim - 1) :] == self.weight.shape[:-1]\n",
    "        x = x.transpose(0, 1)\n",
    "        x = x @ self.weight\n",
    "        x = x.transpose(0, 1)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "        return x"
   ],
   "id": "d125a4c9e667b2b0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T07:18:22.603612Z",
     "start_time": "2025-11-25T07:18:22.597595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m = _NLinear(sequence_length, d_embedding_in, d_embedding_out)\n",
    "m(x).shape"
   ],
   "id": "2cfb68e50f04aea3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "826692f7b0fb1183"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(CV) Training a separate linear layer (i.e. Conv1x1) for each of the spatial embeddings (patch embeddings, pixel embeddings, etc.) of an image (total count: width x height):",
   "id": "c3e772deebc325d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T07:21:10.922647Z",
     "start_time": "2025-11-25T07:21:10.916647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 2\n",
    "width = 4\n",
    "height = 5\n",
    "in_channels = 6\n",
    "out_channels = 7\n",
    "x = torch.randn(batch_size, width, height, in_channels)\n",
    "x.shape"
   ],
   "id": "a19d8fc8bd05e4db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T07:21:36.673783Z",
     "start_time": "2025-11-25T07:21:36.578272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m = _NLinear((width, height), in_channels, out_channels)\n",
    "m(x).shape"
   ],
   "id": "48283022647e485d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, int, int), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m m = \u001B[43m_NLinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m m(x).shape\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 16\u001B[39m, in \u001B[36m_NLinear.__init__\u001B[39m\u001B[34m(self, n, in_features, out_features, bias)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m, in_features: \u001B[38;5;28mint\u001B[39m, out_features: \u001B[38;5;28mint\u001B[39m, bias: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     15\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m()\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m     \u001B[38;5;28mself\u001B[39m.weight = Parameter(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_features\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     17\u001B[39m     \u001B[38;5;28mself\u001B[39m.bias = Parameter(torch.empty(n, out_features)) \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     18\u001B[39m     \u001B[38;5;28mself\u001B[39m.reset_parameters()\n",
      "\u001B[31mTypeError\u001B[39m: empty() received an invalid combination of arguments - got (tuple, int, int), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22d5f7cb1246cd4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
